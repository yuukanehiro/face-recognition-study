import cv2
import dlib
import os

# é¡”æ¤œå‡ºå™¨ã®èª­ã¿è¾¼ã¿
detector = dlib.get_frontal_face_detector()

# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000_fp16.caffemodel')

# é¡”ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
dataset_dir = "known_faces"
face_images = {}

print("ğŸ” known_faces ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...")

for filename in os.listdir(dataset_dir):
    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue

    name = os.path.splitext(filename)[0]
    path = os.path.join(dataset_dir, filename)
    image = cv2.imread(path)

    if image is None:
        print(f"âš ï¸ èª­ã¿è¾¼ã¿å¤±æ•—: {filename}")
        continue

    face_images[name] = image
    print(f"âœ… ç™»éŒ²: {name}")

# ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£ã®é–‹å§‹
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise RuntimeError("âŒ ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")

print("ğŸ¥ é¡”èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆESCã§çµ‚äº†ï¼‰")

while True:
    ret, img = cap.read()
    if not ret:
        print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        break

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    for face in faces:
        x, y, w, h = face.left(), face.top(), face.width(), face.height()
        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)

        face_roi = img[y:y + h, x:x + w]
        if face_roi is None or face_roi.size == 0:
            print("é¡”é ˜åŸŸãŒç©ºã§ã™")
            continue

        blob = cv2.dnn.blobFromImage(face_roi, 1.0, (300, 300), (104.0, 177.0, 123.0))
        net.setInput(blob)
        detections = net.forward()

        confidence = detections[0, 0, 0, 2]
        if confidence > 0.5:
            max_similarity = -1.0
            max_name = 'Unknown'

            # ç™»éŒ²æ¸ˆã¿ã®é¡”å†™çœŸã¨ã®ãƒ«ãƒ¼ãƒ—æ¯”è¼ƒ
            for name, face_image in face_images.items():
                if face_image is None:
                    continue

                # é¡”ã‚µã‚¤ã‚ºã®èª¿æ•´ æ¯”è¼ƒã™ã‚‹ç‚ºã«åŒã˜ã‚µã‚¤ã‚ºã«ã™ã‚‹s
                face_image_resized = cv2.resize(face_image, (face_roi.shape[1], face_roi.shape[0]))

                # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¨ˆç®—ï¼ˆè¼åº¦åˆ†å¸ƒï¼‰
                hist1 = cv2.calcHist([face_roi], [0], None, [256], [0, 256])
                hist2 = cv2.calcHist([face_image_resized], [0], None, [256], [0, 256])

                # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®æ­£è¦åŒ–
                cv2.normalize(hist1, hist1)
                cv2.normalize(hist2, hist2)

                # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ¯”è¼ƒ
                similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)

                # æœ€ã‚‚é«˜ã„é¡ä¼¼åº¦ã®äººç‰©ã‚’è¨˜éŒ²
                if similarity > max_similarity:
                    max_similarity = similarity
                    max_name = name

            # é¡ä¼¼åº¦ã‚’ 0-100 ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆHISTCMP_CORREL ã¯ -1ã€œ1ï¼‰
            similarity_score = int((max_similarity + 1) * 50)  # [-1,1] â†’ [0,100]

            label = f"{max_name} ({similarity_score}%)" if max_name != 'Unknown' else "Unknown âŒ"
            color = (0, 255, 0) if max_name != 'Unknown' else (0, 0, 255)
            cv2.putText(img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

    cv2.imshow('video image', img)
    key = cv2.waitKey(10)
    if key == 27:  # ESC
        print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™")
        break

cap.release()
cv2.destroyAllWindows()